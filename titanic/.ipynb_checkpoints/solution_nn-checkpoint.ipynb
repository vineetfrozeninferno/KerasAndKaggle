{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as skpre\n",
    "import sklearn.model_selection as sksel\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeData(data):\n",
    "    for colName, dataType in zip(data.columns, data.dtypes):\n",
    "        print(colName + \"\\t->\\t\" + str(dataType) + \"\\t->\\t\" + str(np.unique(data[colName]).size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessData(data):\n",
    "    cleanedData = data.drop(labels=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    avgAge = cleanedData[\"Age\"].mean()\n",
    "    cleanedData[\"Age\"] = cleanedData[\"Age\"].fillna(avgAge)\n",
    "    # cleanedData[\"Cabin\"] = cleanedData[\"Cabin\"].fillna(\"Unknown\")\n",
    "    cleanedData[\"Embarked\"] = cleanedData[\"Embarked\"].fillna(\"Unknown\")\n",
    "\n",
    "    data['FamilySize'] = data.SibSp + data.Parch + 1\n",
    "\n",
    "    encodedData = toEnums(cleanedData)\n",
    "    # summarizeData(encodedData)\n",
    "    return encodedData.drop(['SibSp', 'Parch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toEnums(data):\n",
    "    knownNumericalFeatures = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "    for colName in data.columns:\n",
    "        if colName not in knownNumericalFeatures:\n",
    "            # encode all the strings into enums\n",
    "            cleanedInputFeatures = data[colName].apply(lambda x: str(x))\n",
    "            encoder = skpre.LabelEncoder()\n",
    "            encoder.fit(cleanedInputFeatures)\n",
    "            data[colName] = encoder.transform(cleanedInputFeatures)\n",
    "        else:\n",
    "            # scale the features correctly\n",
    "            data[colName] = skpre.scale(data[colName])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "titanicData = pd.read_csv(\"train.csv\")\n",
    "processedTitanicData = preProcessData(titanicData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = sksel.train_test_split(processedTitanicData, test_size=(4/5))\n",
    "\n",
    "trainingResultsDF = trainData[\"Survived\"]\n",
    "trainingFeaturesDF = trainData.drop(\"Survived\", axis=1)\n",
    "\n",
    "testResultsDF = testData[\"Survived\"]\n",
    "testFeaturesDF = testData.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 5, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingFeatures = trainingFeaturesDF.values.reshape(trainingFeaturesDF.shape[0], 5, 1)\n",
    "testFeatures = testFeaturesDF.values.reshape(testFeaturesDF.shape[0], 5, 1)\n",
    "trainingFeatures = trainingFeatures.astype('float32')\n",
    "trainingFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingResults = np_utils.to_categorical(trainingResultsDF.values, 2)\n",
    "testResults = np_utils.to_categorical(testResultsDF.values, 2)\n",
    "trainingResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "178/178 [==============================] - 1s 6ms/step - loss: 0.7137 - acc: 0.5618\n",
      "Epoch 2/30\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.7027 - acc: 0.5449\n",
      "Epoch 3/30\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.6973 - acc: 0.5449\n",
      "Epoch 4/30\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.7043 - acc: 0.5112\n",
      "Epoch 5/30\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.7037 - acc: 0.4438\n",
      "Epoch 6/30\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.7006 - acc: 0.4888\n",
      "Epoch 7/30\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.7034 - acc: 0.5000\n",
      "Epoch 8/30\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.6976 - acc: 0.4944\n",
      "Epoch 9/30\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.6908 - acc: 0.5337\n",
      "Epoch 10/30\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.6876 - acc: 0.5281\n",
      "Epoch 11/30\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.6898 - acc: 0.5169\n",
      "Epoch 12/30\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.6910 - acc: 0.4944\n",
      "Epoch 13/30\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.6856 - acc: 0.5730\n",
      "Epoch 14/30\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.6877 - acc: 0.5393\n",
      "Epoch 15/30\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.6879 - acc: 0.6124\n",
      "Epoch 16/30\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.6863 - acc: 0.6067\n",
      "Epoch 17/30\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.6806 - acc: 0.6124\n",
      "Epoch 18/30\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.6870 - acc: 0.6124\n",
      "Epoch 19/30\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.6881 - acc: 0.6124\n",
      "Epoch 20/30\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.6883 - acc: 0.6124\n",
      "Epoch 21/30\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.6833 - acc: 0.6124\n",
      "Epoch 22/30\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.6793 - acc: 0.6124\n",
      "Epoch 23/30\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.6834 - acc: 0.6124\n",
      "Epoch 24/30\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.6782 - acc: 0.6124\n",
      "Epoch 25/30\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.6769 - acc: 0.6124\n",
      "Epoch 26/30\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.6719 - acc: 0.6124\n",
      "Epoch 27/30\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.6750 - acc: 0.6124\n",
      "Epoch 28/30\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.6736 - acc: 0.6124\n",
      "Epoch 29/30\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.6742 - acc: 0.6124\n",
      "Epoch 30/30\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.6765 - acc: 0.6124\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1, activation='relu', input_shape=(5,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(17, activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "#model.add(Dense(13, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit model on training data\n",
    "history = model.fit(x=trainingFeatures, y=trainingResults,batch_size=50, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 1s 708us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6710686640184357, 0.6171107994389902]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testFeatures, testResults, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
